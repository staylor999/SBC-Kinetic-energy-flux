{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7b8404-8707-4290-8fa3-402a133bc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# included modules necessary for the code for this notebook.\n",
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import gsw\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d80bf9-f1ce-4e48-a95e-38761aca5f43",
   "metadata": {},
   "source": [
    "This is a snippet (Jan 2012) of the kinetic energy flux code to show how to apply the coarse graining approach, fairly hard-coded.\n",
    "Breaks down the components of the flux calculations as outlined in equation (1) in the manuscript\n",
    "\n",
    "1) load in the HF radar data from whereever it is saved\n",
    "2) extract the latitude, longitude, and velocity components\n",
    "3) Apply the filter function where radius is the filtered scale - for the purposes of the study, 7 km was used, but any filtered scale could be applied\n",
    "4) create the derivative grid space, that is different from the latitude and longitudes pulled from the HF radar\n",
    "5) create the stencil for the appropriate filtered scale (7 km shown below)\n",
    "6) apply the coarse graining function and filtered scale/stencil to the different components of the kinetic energy flux computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "80c7ebe3-37b5-4df1-878c-7e26674d1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'a' is the data load file - load in your you data from wherever you stored it\n",
    "a = xr.open_mfdataset('/export/data1/jbenjami/Data/SMODE/HF_Radar/HFRADAR_US_West_Coast_2km_Resolution_Hourly_RTV_best/HFRADAR_US_West_Coast_2km_Resolution_Hourly_RTV_best_2012_01*.nc', parallel=True)\n",
    "latitudes = a['lat']\n",
    "latitude = latitudes[153:264].values\n",
    "longitudes = a['lon']\n",
    "longitude = longitudes[449:593].values\n",
    "uvel = a['u']\n",
    "Janu_mean = uvel[:,153:264,449:593].values\n",
    "vvel = a['v']\n",
    "Janv_mean = vvel[:,153:264,449:593].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb4c0f8a-6e79-473f-b65b-66bd4bfaf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the velocity data on the lat/lon grid and applies the top hat filter of the coarse graining method at the appropriate radius, where the radius is the filtering scale\n",
    "def observ(velocity, lat, lon, radius):\n",
    "    ny, nx = velocity.shape\n",
    "    \n",
    "    start_row = max(lat - radius, 0)\n",
    "    # print(start_row)\n",
    "    end_row = min(lat + radius + 1, ny)\n",
    "    # print(end_row)\n",
    "    \n",
    "    start_col = max(lon - radius, 0)\n",
    "    # print(start_col)\n",
    "    end_col = min(lon + radius + 1, nx)\n",
    "    # print(end_col)\n",
    "    \n",
    "    return velocity[start_row:end_row, start_col:end_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644c88d-8afa-444b-a5af-a87195c665dc",
   "metadata": {},
   "source": [
    "Setting up the grid initially and only needed once for all spatial plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf244c4-dff5-486c-8199-0526484d2b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1999.56086808]\n",
      "[1999.1366931]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1999.34878059])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determining dy - constant over all longitude lines\n",
    "long = [longitude[25], longitude[25]]\n",
    "lat1 = [latitude[50], latitude[51]]\n",
    "lat2 = [latitude[54], latitude[55]]\n",
    "distance1 = gsw.distance(long, lat1)\n",
    "distance2 = gsw.distance(long, lat2)\n",
    "\n",
    "dy = (distance1+distance2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a3338-aa07-4386-b150-5d4ad97aee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining dx - not constant over all latitude lines\n",
    "dxs = []\n",
    "for i in range(0, len(latitude)):\n",
    "    long = [longitude[0], longitude[1]]\n",
    "    lat = [latitude[i], latitude[i]]\n",
    "    distance = gsw.distance(long, lat)\n",
    "    dxs.append(distance)\n",
    "    \n",
    "dx = np.squeeze(dxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28caf49-622d-4c21-92a4-9f0d3e39d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These are the arrays of latitude and longitude on which the velocity derivatives will lie\n",
    "The derivatives aren't on the generic latitude/longitude grid provided because in computing derivatives for \n",
    "vorticity, divergence, strain, etc, the grid gets shifted\n",
    "\"\"\"\n",
    "dlat = (latitude[1]-latitude[0])/2\n",
    "lat = latitude + dlat\n",
    "dlon = np.abs((longitude[0]-longitude[1])/2)\n",
    "lon = longitude + dlon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd10492-16d4-4ed7-9e0a-dae0752ae4eb",
   "metadata": {},
   "source": [
    "Creating the stencil that will be called - this shows the filter stencil of values that fall within the filtered scale and anything beyond will not be applied to the calculation in that iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0440c33-73fd-4d09-81dd-7e2f6e99f66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan,  1.,  1.,  1., nan, nan],\n",
       "       [nan,  1.,  1.,  1.,  1.,  1., nan],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [nan,  1.,  1.,  1.,  1.,  1., nan],\n",
       "       [nan, nan,  1.,  1.,  1., nan, nan]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l = 7 km\n",
    "np.sqrt((3*np.nanmean(dx))**2+(1*dy)**2)\n",
    "stencil7 = np.ones((7,7))\n",
    "stencil7[0,0] = np.nan\n",
    "stencil7[0,6] = np.nan\n",
    "stencil7[0,5] = np.nan\n",
    "stencil7[1,6] = np.nan\n",
    "stencil7[0,1] = np.nan\n",
    "stencil7[1,0] = np.nan\n",
    "stencil7[6,0] = np.nan\n",
    "stencil7[5,0] = np.nan\n",
    "stencil7[6,1] = np.nan\n",
    "stencil7[6,6] = np.nan\n",
    "stencil7[6,5] = np.nan\n",
    "stencil7[5,6] = np.nan\n",
    "stencil7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1629e36-1aad-4b11-8d52-ed8cf6acec47",
   "metadata": {
    "tags": []
   },
   "source": [
    "filtered velocites - 2 day average to eliminate tidal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef32220-f45c-4a49-af5b-97d80a327a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_mean = np.full_like(Janu_mean, np.nan)\n",
    "av_mean = np.full_like(Janu_mean, np.nan)\n",
    "\n",
    "for p in range(0, len(Janu_mean)):\n",
    "    au_mean[p] = np.nanmean(Janu_mean[p:(p+48),:,:], axis=0)\n",
    "    av_mean[p] = np.nanmean(Janv_mean[p:(p+48),:,:], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daace00-bfc8-4ba4-9d66-6c9d912fc966",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculating the kinetic energy flux and each component as delineated in equation (1) in the manuscript\n",
    "\n",
    "I personally saved the calculations as I went along (not shown here) - you can save whatever data you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3eea75-885b-4892-be48-3a8883d46bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first for the u-velocity\n",
    "filteredu = np.full(((744,111,144)), np.nan)\n",
    "for p in range(0,744): \n",
    "    u = au_mean[p,:,:]\n",
    "    ufiltered = np.full((111,144), np.nan)\n",
    "\n",
    "    velocity = u\n",
    "    radius = 3\n",
    "\n",
    "    for i in range(radius,len(latitude)-radius):\n",
    "        for j in range(radius, len(longitude)-radius):\n",
    "            result = observ(velocity, i, j, radius)*stencil7\n",
    "            # print(result)\n",
    "            average = (np.nanmean(result))\n",
    "            # print(average)\n",
    "            ufiltered[i,j] = average\n",
    "    filteredu[p] = ufiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d48784fa-111a-4c8c-a6e6-585d4b4a1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered 2 km/SCA kinetic energy flux u-velocity derivatives\n",
    "dudx5 = np.full(((744,(len(latitude)-1),(len(longitude)-1))), np.nan) # one less on each dimension than the filteredu\n",
    "dudy5 = np.full_like(dudx5, np.nan)\n",
    "for p in range(0, 744):\n",
    "    ufiltered = filteredu[p,:,:]\n",
    "    dufildx5 = np.full((len(latitude)-1, len(longitude)-1),np.nan)\n",
    "    dufildy5 = np.full_like(dufildx5, np.nan)\n",
    "    for j in range(radius, (len(latitude)-radius-1)):\n",
    "        for i in range(radius, (len(longitude)-radius-1)):\n",
    "            dufildx5[j,i] = (((ufiltered[j,(i+1)]-ufiltered[j,i])/dx[j]) + ((ufiltered[(j+1),(i+1)]-ufiltered[(j+1),i])/dx[(j+1)]))/2\n",
    "            dufildy5[j,i] = ((ufiltered[(j+1),i]-ufiltered[j,i])/dy + (ufiltered[(j+1),(i+1)]-ufiltered[j, (i+1)])/dy)/2\n",
    "    dudx5[p]=dufildx5\n",
    "    dudy5[p]=dufildy5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4081c13-8512-4d0b-89e1-0175d04d614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for the v-velocity\n",
    "filteredv = np.full_like(filteredu, np.nan)\n",
    "for p in range(0, 744):\n",
    "    v = av_mean[p,:,:]\n",
    "    vfiltered = np.full_like(ufiltered, np.nan)\n",
    "\n",
    "    velocity = v\n",
    "    radius = 3\n",
    "\n",
    "    for i in range(radius, len(latitude)-radius):\n",
    "        for j in range(radius, len(longitude)-radius):\n",
    "            result = observ(velocity, i, j, radius)*stencil7\n",
    "    #         print(result.shape)\n",
    "            average = (np.nanmean(result))\n",
    "            vfiltered[i,j] = average\n",
    "    filteredv[p] = vfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8919bf11-5bbf-45b8-9a08-5d6a547d44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered 2 km/SCA kinetic energy flux v-velocity derivatives\n",
    "dvdx5 = np.full(((744,(len(latitude)-1),(len(longitude)-1))), np.nan) # one less on each dimension than the filteredu\n",
    "dvdy5 = np.full_like(dvdx5, np.nan)\n",
    "for p in range(0, 744):\n",
    "    vfiltered = filteredv[p,:,:]\n",
    "    dvfildx5 = np.full((len(latitude)-1, len(longitude)-1),np.nan)\n",
    "    dvfildy5 = np.full_like(dvfildx5, np.nan)\n",
    "    for j in range(radius, (len(latitude)-(radius-1))):\n",
    "        for i in range(radius, (len(longitude)-(radius-1))):\n",
    "            dvfildx5[j,i] = (((vfiltered[j,(i+1)]-vfiltered[j,i])/dx[j]) + ((vfiltered[(j+1),(i+1)]-vfiltered[(j+1),i])/dx[(j+1)]))/2\n",
    "            dvfildy5[j,i] = ((vfiltered[(j+1),i]-vfiltered[j,i])/dy + (vfiltered[(j+1),(i+1)]-vfiltered[j, (i+1)])/dy)/2\n",
    "    dvdx5[p]=dvfildx5\n",
    "    dvdy5[p]=dvfildy5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c3bc25fa-c4b7-4b31-8035-aefcb114761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26107/2760086185.py:18: RuntimeWarning: Mean of empty slice\n",
      "  average = (np.nanmean(result))\n",
      "/tmp/ipykernel_26107/2760086185.py:32: RuntimeWarning: Mean of empty slice\n",
      "  average = (np.nanmean(result))\n",
      "/tmp/ipykernel_26107/2760086185.py:46: RuntimeWarning: Mean of empty slice\n",
      "  average = (np.nanmean(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now taking velocity squared\n",
    "first u-velocity squared\n",
    "\"\"\"\n",
    "filteredusqrd = np.full_like(filteredu, np.nan)\n",
    "filteredvsqrd = np.full_like(filteredu, np.nan)\n",
    "filtereduv = np.full_like(filteredu, np.nan)\n",
    "for p in range(0,744):\n",
    "    u = au_mean[p,:,:]\n",
    "    v = av_mean[p,:,:]\n",
    "    usqrdfiltered = np.full_like(ufiltered, np.nan)\n",
    "\n",
    "    velocity = u**2\n",
    "    radius = 3\n",
    "\n",
    "    for i in range(radius,len(latitude)-radius):\n",
    "        for j in range(radius, len(longitude)-radius):\n",
    "            result = observ(velocity, i, j, radius)*stencil7\n",
    "    #         print(result.shape)\n",
    "            average = (np.nanmean(result))\n",
    "            usqrdfiltered[i,j] = average\n",
    "    filteredusqrd[p] = usqrdfiltered\n",
    "\n",
    "# now v-velocity squared\n",
    "    vsqrdfiltered = np.full_like(ufiltered, np.nan)\n",
    "\n",
    "    velocity = v**2\n",
    "    radius = 3\n",
    "\n",
    "    for i in range(radius,len(latitude)-radius):\n",
    "        for j in range(radius, len(longitude)-radius):\n",
    "            result = observ(velocity, i, j, radius)*stencil7\n",
    "    #         print(result.shape)\n",
    "            average = (np.nanmean(result))\n",
    "            vsqrdfiltered[i,j] = average\n",
    "    filteredvsqrd[p] = vsqrdfiltered\n",
    "    \n",
    "# now u-v velocity\n",
    "    uvfiltered = np.full_like(ufiltered, np.nan)\n",
    "\n",
    "    velocity = u*v\n",
    "    radius = 3\n",
    "\n",
    "    for i in range(radius,len(latitude)-radius):\n",
    "        for j in range(radius, len(longitude)-radius):\n",
    "            result = observ(velocity, i, j, radius)*stencil7\n",
    "    #         print(result.shape)\n",
    "            average = (np.nanmean(result))\n",
    "            uvfiltered[i,j] = average\n",
    "    filtereduv[p] = uvfiltered\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ba0ab186-d522-4c23-9be8-137ce0b9ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculating tau - so first calculate tau on the longitude/latitude grid then average to place on the lon/lat grid\n",
    "uutau = np.full_like(filteredu, np.nan)\n",
    "tauuu5 = np.full(((744, (len(latitude)-1), (len(longitude)-1))), np.nan)\n",
    "for p in range(0, 744):\n",
    "    uutau[p] = filteredusqrd[p,:,:] - filteredu[p,:,:]*filteredu[p,:,:]\n",
    "\n",
    "for p in range(0, 744):\n",
    "    tau = uutau[p,:,:]\n",
    "    Tau = np.full_like(dufildx5, np.nan)\n",
    "    for i in range(radius, len(latitude)-radius):\n",
    "        for j in range(radius, len(longitude)-radius):\n",
    "            Tau[i,j] = (tau[i,j]+tau[i,j+1]+tau[i+1,j+1]+tau[i+1,j])/4\n",
    "    tauuu5[p] = Tau\n",
    "    \n",
    "vvtau = np.full_like(filteredu, np.nan)\n",
    "tauvv5 = np.full(((744, (len(latitude)-1), (len(longitude)-1))), np.nan)\n",
    "for p in range(0, 744):\n",
    "    vvtau[p] = filteredvsqrd[p,:,:] - filteredv[p,:,:]*filteredv[p,:,:]\n",
    "\n",
    "for p in range(0, 744):\n",
    "    tau = vvtau[p,:,:]\n",
    "    Tau = np.full_like(dufildx5, np.nan)\n",
    "    for i in range(radius, len(latitude)-radius):\n",
    "        for j in range(radius, len(longitude)-radius):\n",
    "            Tau[i,j] = (tau[i,j]+tau[i,j+1]+tau[i+1,j+1]+tau[i+1,j])/4\n",
    "    tauvv5[p] = Tau\n",
    "    \n",
    "uvtau = np.full_like(filteredu, np.nan)\n",
    "tauuv5 = np.full(((744, (len(latitude)-1), (len(longitude)-1))), np.nan)\n",
    "for p in range(0, 744):\n",
    "    uvtau[p] = filtereduv[p,:,:] - filteredu[p,:,:]*filteredv[p,:,:]\n",
    "\n",
    "for p in range(0, 744):\n",
    "    tau = uvtau[p,:,:]\n",
    "    Tau = np.full_like(dufildx5, np.nan)\n",
    "    for i in range(radius, len(latitude)-radius):\n",
    "        for j in range(radius, len(longitude)-radius):\n",
    "            Tau[i,j] = (tau[i,j]+tau[i,j+1]+tau[i+1,j+1]+tau[i+1,j])/4\n",
    "    tauuv5[p] = Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9db62a55-3315-4573-ad48-1ec9e0614881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, take each component, and calculate the flux\n",
    "pi = -(tauuv5*(dudy5+dvdx5)+tauuu5*dudx5+tauvv5*dvdy5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SMODE]",
   "language": "python",
   "name": "conda-env-SMODE-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
